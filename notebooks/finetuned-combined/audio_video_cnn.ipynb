{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm-A1pWMR3oa",
        "outputId": "d48a919c-e158-4702-aac5-986f7206e18f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install facenet-pytorch\n",
        "!python3 -m pip install face_alignment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNr_mImAjLT7",
        "outputId": "290ed857-0d49-4959-ff9f-a3f79166dc05"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m1.7/1.9 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.31.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (0.16.0+cu121)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2024.2.2)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->facenet-pytorch) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->facenet-pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->facenet-pytorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->facenet-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->facenet-pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->facenet-pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->facenet-pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->facenet-pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision->facenet-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision->facenet-pytorch) (1.3.0)\n",
            "Installing collected packages: facenet-pytorch\n",
            "Successfully installed facenet-pytorch-2.5.3\n",
            "Collecting face_alignment\n",
            "  Downloading face_alignment-1.4.1-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from face_alignment) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_alignment) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.10/dist-packages (from face_alignment) (1.11.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from face_alignment) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from face_alignment) (4.8.0.76)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from face_alignment) (4.66.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from face_alignment) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->face_alignment) (0.41.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->face_alignment) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->face_alignment) (1.3.0)\n",
            "Installing collected packages: face_alignment\n",
            "Successfully installed face_alignment-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SP57JsruRqX5"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "from facenet_pytorch import MTCNN\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import face_alignment\n",
        "import dlib\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GoogLeNetModified(models.GoogLeNet):\n",
        "    def _transform_input(self, x):\n",
        "        if x.size(1) == 1:\n",
        "            # If the input has only one channel, replicate it to create three channels\n",
        "            x = x.expand(-1, 3, -1, -1)\n",
        "\n",
        "        x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
        "        x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
        "        x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
        "        x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
        "\n",
        "        return x\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.features = GoogLeNetModified()\n",
        "        # Modify the first layer to accept 3 channel input (for RGB images)\n",
        "        self.features.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        # Modify the final layer to output the desired feature size\n",
        "        self.features.fc = nn.Linear(self.features.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "\n",
        "        # Assuming the output is a tensor inside the GoogLeNetOutputs object\n",
        "        logits_tensor = x.logits if hasattr(x, 'logits') else x  # Adjust accordingly based on the structure\n",
        "\n",
        "        # Apply softmax directly on the logits tensor\n",
        "        x_softmax = torch.nn.functional.softmax(logits_tensor, dim=1)\n",
        "        return x_softmax\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oLkWoD6pRrAb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frame(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    mid_frame_index = frame_count // 2  # Index of the frame in the middle of the video\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, mid_frame_index)\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        cap.release()\n",
        "        return frame\n",
        "    else:\n",
        "        cap.release()\n",
        "        return None"
      ],
      "metadata": {
        "id": "gWDrEH00iv6H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_face(frame):\n",
        "    mtcnn = MTCNN()\n",
        "    boxes, _ = mtcnn.detect(frame)\n",
        "    if boxes is not None:\n",
        "        # Assuming only one face in the frame\n",
        "        box = boxes[0]\n",
        "        x1, y1, x2, y2 = box\n",
        "        # Crop the frame to the detected face\n",
        "        cropped_frame = frame[int(y1):int(y2), int(x1):int(x2)]\n",
        "        return cropped_frame\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "_eeDIIORixs-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to download the pretrained face alignment model if it doesn't exist\n",
        "def download_face_alignment_model(url, save_path):\n",
        "    if not os.path.exists(save_path):\n",
        "        print(\"Downloading pretrained face alignment model...\")\n",
        "        response = requests.get(url)\n",
        "        with open(save_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(\"Download complete.\")\n",
        "\n",
        "# Specify the URL of the pretrained face alignment model\n",
        "face_alignment_model_url = \"https://github.com/1adrianb/face-alignment-models/releases/download/2.0.1/2DFAN4-11f355bf06.pth.tar\"\n",
        "\n",
        "# Download the pretrained face alignment model if it doesn't exist\n",
        "face_alignment_model_path = os.path.abspath(\"2DFAN4-11f355bf06.pth.tar\")\n",
        "download_face_alignment_model(face_alignment_model_url, face_alignment_model_path)\n",
        "\n",
        "# Initialize face alignment model\n",
        "fa = face_alignment.FaceAlignment(2, flip_input=False, device='cpu')  # 2 corresponds to 2D landmarks\n",
        "\n",
        "def align_face(frame):\n",
        "    # Perform face alignment\n",
        "    aligned_faces = fa.get_landmarks(frame)\n",
        "    if aligned_faces is not None:\n",
        "        aligned_face = aligned_faces[0]  # Assuming only one face in the frame\n",
        "        return aligned_face\n",
        "    else:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "pWavua0jl3ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f7d8f6-1efb-4e44-e07c-0b7d75e656b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pretrained face alignment model...\n",
            "Download complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" to /root/.cache/torch/hub/checkpoints/s3fd-619a316812.pth\n",
            "100%|██████████| 85.7M/85.7M [03:27<00:00, 432kB/s]\n",
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/3DFAN4-4a694010b9.zip\" to /root/.cache/torch/hub/checkpoints/3DFAN4-4a694010b9.zip\n",
            "100%|██████████| 91.9M/91.9M [00:04<00:00, 20.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(frame):\n",
        "    # Convert the frame to a PIL Image\n",
        "    frame_pil = Image.fromarray(frame.astype('uint8'))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    frame_pil = frame_pil.convert('L')\n",
        "\n",
        "    # Resize and normalize the frame\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485], std=[0.229]),  # For grayscale images, only 1 channel\n",
        "    ])\n",
        "    img_tensor = transform(frame_pil)\n",
        "    return img_tensor"
      ],
      "metadata": {
        "id": "o5gBfMkuitP0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_spectrogram(image_path):\n",
        "    img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485], std=[0.229]),  # For grayscale images, only 1 channel\n",
        "    ])\n",
        "    img_tensor = transform(img)\n",
        "    # img_tensor = img_tensor.unsqueeze(0)  # Add batch dimension\n",
        "    return img_tensor"
      ],
      "metadata": {
        "id": "x5iAGoZ_yUMX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_spectrogram_dataset(input_folder):\n",
        "    X = []\n",
        "    y = []\n",
        "    # List all files in the input folder\n",
        "    files = os.listdir(input_folder)\n",
        "    # Iterate over files in the folder\n",
        "    for filename in files:\n",
        "        if filename.endswith(\".png\"):  # Assuming mel spectrograms are stored as PNG files\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "            img_tensor = preprocess_spectrogram(input_path)\n",
        "            X.append(img_tensor)\n",
        "            # Extract label from filename (assuming filename is in format \"abc_IEO_label_xyz.png\")\n",
        "            label = filename.split(\"_\")[2]\n",
        "            if label == \"HAP\":\n",
        "                y.append(0)\n",
        "            elif label == \"SAD\":\n",
        "                y.append(1)\n",
        "            elif label == \"ANG\":\n",
        "                y.append(2)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "ONxd6uaQyYT8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(input_folder):\n",
        "    X = []\n",
        "    y = []\n",
        "    video_files = [file for file in os.listdir(input_folder) if file.endswith(\".flv\")]\n",
        "    for video_file in tqdm(video_files):\n",
        "        video_path = os.path.join(input_folder, video_file)\n",
        "        frame = extract_frame(video_path)\n",
        "        if frame is not None:\n",
        "            cropped_face = detect_face(frame)\n",
        "            if cropped_face is not None:\n",
        "                preprocessed_face = preprocess_image(cropped_face)\n",
        "                X.append(preprocessed_face)\n",
        "                label = video_file.split(\"_\")[2].split(\".\")[0]  # Adjusted to handle different file extensions\n",
        "                if label == \"HAP\":\n",
        "                    y.append(0)\n",
        "                elif label == \"SAD\":\n",
        "                    y.append(1)\n",
        "                elif label == \"ANG\":\n",
        "                    y.append(2)\n",
        "            else:\n",
        "                print(f\"No face detected in {video_file}. Skipping.\")\n",
        "        else:\n",
        "            print(f\"Failed to extract frame from {video_file}. Skipping.\")\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "RZPMwNWJi5p3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConcatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X1, X2, y):\n",
        "        self.X1 = X1\n",
        "        self.X2 = X2\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img1 = self.X1[idx]\n",
        "        img2 = self.X2[idx]\n",
        "        label = self.y[idx]\n",
        "        # Concatenate images along the channel dimension\n",
        "        concatenated_img = torch.cat((img1, img2), dim=2)\n",
        "        return concatenated_img, label"
      ],
      "metadata": {
        "id": "O0bI2bJNzZ9r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "    for inputs, labels in tqdm(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_preds += (predicted == labels).sum().item()\n",
        "        total_preds += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    accuracy = correct_preds / total_preds\n",
        "    return epoch_loss, accuracy"
      ],
      "metadata": {
        "id": "Q5--S5JwTTw1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, criterion, test_loader, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(test_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_preds += (predicted == labels).sum().item()\n",
        "            total_preds += labels.size(0)\n",
        "    epoch_loss = running_loss / len(test_loader.dataset)\n",
        "    accuracy = correct_preds / total_preds\n",
        "    return epoch_loss, accuracy"
      ],
      "metadata": {
        "id": "ajpo8J6kTUjD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = '/content/drive/MyDrive/csci535/videos'\n",
        "input_folder_spec = '/content/drive/MyDrive/csci535/melspec'\n",
        "\n",
        "# Check if input folder exists\n",
        "if not os.path.exists(input_folder):\n",
        "    print(\"Input folder does not exist.\")\n",
        "    sys.exit(1)\n",
        "# Check if input folder exists\n",
        "if not os.path.exists(input_folder_spec):\n",
        "    print(\"Input folder does not exist.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Load dataset and split into train and test sets\n",
        "X, y = load_dataset(input_folder)\n",
        "X_spec, y_spec = load_spectrogram_dataset(input_folder_spec)\n",
        "\n",
        "print(f\"Total number of samples: {len(X)}\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print(f\"Number of train samples (video): {len(X_train)}\", f\"Number of test samples: {len(X_test)}\")\n",
        "X_train_spec, X_test_spec, y_train_spec, y_test_spec = train_test_split(X_spec, y_spec, test_size=0.3, random_state=42)\n",
        "print(f\"Number of train samples (audio): {len(X_train_spec)}\", f\"Number of test samples: {len(X_test_spec)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D29Ahtfz2HAb",
        "outputId": "c1df5fd5-174c-484b-ab0e-11e9c18605e7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 273/273 [01:00<00:00,  4.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of samples: 273\n",
            "Number of train samples (video): 191 Number of test samples: 82\n",
            "Number of train samples (audio): 191 Number of test samples: 82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = CNN(num_classes=3)  # 3 classes for HAPPY, SAD, ANGRY\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "_lr = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=_lr)\n",
        "\n",
        "# Concatenate datasets\n",
        "train_dataset = ConcatDataset(X_train, X_train_spec, y_train)\n",
        "test_dataset = ConcatDataset(X_test, X_test_spec, y_test)\n",
        "\n",
        "# Create data loaders\n",
        "_bs = 32\n",
        "# train_loader = torch.utils.data.DataLoader(list(zip(X_train, y_train)), batch_size=_bs, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(list(zip(X_test, y_test)), batch_size=_bs)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=_bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=_bs)\n",
        "\n",
        "\n",
        "print(f\"Batch size: {_bs}\", f\"lr: {_lr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3xLVy9d2O5d",
        "outputId": "a8b7516c-dc33-486d-ef7f-44c19faf0328"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: 32 lr: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"Epoch \" + str(epoch))\n",
        "    train_loss, train_accuracy = train_model(model, criterion, optimizer, train_loader, device)\n",
        "    test_loss, test_accuracy = test_model(model, criterion, test_loader, device)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0upA86L2S47",
        "outputId": "77ff1978-ff32-47bf-ab3c-08678b420782"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:22<00:00, 23.83s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 1.1239, Train Accuracy: 0.3246, Test Loss: 1.1079, Test Accuracy: 0.3415\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:08<00:00, 21.43s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50, Train Loss: 1.0645, Train Accuracy: 0.4398, Test Loss: 1.1955, Test Accuracy: 0.3415\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:06<00:00, 21.13s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50, Train Loss: 1.0207, Train Accuracy: 0.5079, Test Loss: 1.1943, Test Accuracy: 0.3415\n",
            "Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:07<00:00, 21.24s/it]\n",
            "100%|██████████| 3/3 [00:22<00:00,  7.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50, Train Loss: 0.9949, Train Accuracy: 0.5445, Test Loss: 1.2032, Test Accuracy: 0.3415\n",
            "Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:11<00:00, 21.97s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50, Train Loss: 0.9629, Train Accuracy: 0.5707, Test Loss: 1.2059, Test Accuracy: 0.3415\n",
            "Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.75s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50, Train Loss: 0.9739, Train Accuracy: 0.5602, Test Loss: 1.2094, Test Accuracy: 0.3415\n",
            "Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:01<00:00, 20.17s/it]\n",
            "100%|██████████| 3/3 [00:19<00:00,  6.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50, Train Loss: 0.9412, Train Accuracy: 0.6387, Test Loss: 1.1970, Test Accuracy: 0.3415\n",
            "Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:06<00:00, 21.14s/it]\n",
            "100%|██████████| 3/3 [00:22<00:00,  7.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50, Train Loss: 0.8986, Train Accuracy: 0.6597, Test Loss: 1.1783, Test Accuracy: 0.3293\n",
            "Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:10<00:00, 21.78s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50, Train Loss: 0.8978, Train Accuracy: 0.6649, Test Loss: 1.2086, Test Accuracy: 0.3415\n",
            "Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.75s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50, Train Loss: 0.9376, Train Accuracy: 0.6126, Test Loss: 1.1518, Test Accuracy: 0.3659\n",
            "Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:03<00:00, 20.65s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50, Train Loss: 0.8698, Train Accuracy: 0.6702, Test Loss: 1.0748, Test Accuracy: 0.4634\n",
            "Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:03<00:00, 20.62s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  7.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/50, Train Loss: 0.8876, Train Accuracy: 0.6597, Test Loss: 1.1684, Test Accuracy: 0.3780\n",
            "Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.75s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50, Train Loss: 0.8411, Train Accuracy: 0.7120, Test Loss: 0.9918, Test Accuracy: 0.5366\n",
            "Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.70s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50, Train Loss: 0.8783, Train Accuracy: 0.6545, Test Loss: 1.1551, Test Accuracy: 0.3780\n",
            "Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:03<00:00, 20.62s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/50, Train Loss: 0.8555, Train Accuracy: 0.6806, Test Loss: 1.0228, Test Accuracy: 0.5244\n",
            "Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.78s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/50, Train Loss: 0.8278, Train Accuracy: 0.7382, Test Loss: 0.9837, Test Accuracy: 0.5610\n",
            "Epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:06<00:00, 21.01s/it]\n",
            "100%|██████████| 3/3 [00:22<00:00,  7.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/50, Train Loss: 0.8091, Train Accuracy: 0.7644, Test Loss: 1.0746, Test Accuracy: 0.4146\n",
            "Epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:05<00:00, 20.85s/it]\n",
            "100%|██████████| 3/3 [00:22<00:00,  7.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/50, Train Loss: 0.8847, Train Accuracy: 0.6597, Test Loss: 1.0256, Test Accuracy: 0.5122\n",
            "Epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:03<00:00, 20.64s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/50, Train Loss: 0.8449, Train Accuracy: 0.6806, Test Loss: 0.9483, Test Accuracy: 0.5854\n",
            "Epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:03<00:00, 20.62s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/50, Train Loss: 0.8212, Train Accuracy: 0.7277, Test Loss: 1.0266, Test Accuracy: 0.5122\n",
            "Epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.73s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/50, Train Loss: 0.8181, Train Accuracy: 0.7435, Test Loss: 1.0892, Test Accuracy: 0.4390\n",
            "Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.81s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50, Train Loss: 0.8019, Train Accuracy: 0.7382, Test Loss: 1.0430, Test Accuracy: 0.4756\n",
            "Epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:05<00:00, 20.94s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/50, Train Loss: 0.8036, Train Accuracy: 0.7382, Test Loss: 1.0574, Test Accuracy: 0.5000\n",
            "Epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.81s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/50, Train Loss: 0.7972, Train Accuracy: 0.7539, Test Loss: 1.0665, Test Accuracy: 0.4756\n",
            "Epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.71s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/50, Train Loss: 0.8210, Train Accuracy: 0.7277, Test Loss: 1.1164, Test Accuracy: 0.4268\n",
            "Epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.81s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/50, Train Loss: 0.7630, Train Accuracy: 0.7906, Test Loss: 1.0097, Test Accuracy: 0.5366\n",
            "Epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:03<00:00, 20.65s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/50, Train Loss: 0.7457, Train Accuracy: 0.8168, Test Loss: 1.1972, Test Accuracy: 0.3537\n",
            "Epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.77s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/50, Train Loss: 0.7955, Train Accuracy: 0.7592, Test Loss: 0.9623, Test Accuracy: 0.5610\n",
            "Epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:03<00:00, 20.62s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50, Train Loss: 0.7825, Train Accuracy: 0.7696, Test Loss: 1.1829, Test Accuracy: 0.3537\n",
            "Epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:03<00:00, 20.56s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/50, Train Loss: 0.7779, Train Accuracy: 0.7801, Test Loss: 1.0392, Test Accuracy: 0.5000\n",
            "Epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.78s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50, Train Loss: 0.7500, Train Accuracy: 0.8010, Test Loss: 0.9459, Test Accuracy: 0.5976\n",
            "Epoch 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:06<00:00, 21.06s/it]\n",
            "100%|██████████| 3/3 [00:22<00:00,  7.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/50, Train Loss: 0.7590, Train Accuracy: 0.7801, Test Loss: 0.9783, Test Accuracy: 0.5366\n",
            "Epoch 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:07<00:00, 21.26s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/50, Train Loss: 0.7478, Train Accuracy: 0.8063, Test Loss: 1.1484, Test Accuracy: 0.4024\n",
            "Epoch 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:07<00:00, 21.28s/it]\n",
            "100%|██████████| 3/3 [00:22<00:00,  7.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/50, Train Loss: 0.7764, Train Accuracy: 0.7696, Test Loss: 1.0568, Test Accuracy: 0.4756\n",
            "Epoch 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:05<00:00, 20.95s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/50, Train Loss: 0.7899, Train Accuracy: 0.7382, Test Loss: 1.1128, Test Accuracy: 0.4390\n",
            "Epoch 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:05<00:00, 20.84s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/50, Train Loss: 0.7682, Train Accuracy: 0.7801, Test Loss: 1.0505, Test Accuracy: 0.4878\n",
            "Epoch 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:05<00:00, 20.94s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/50, Train Loss: 0.7373, Train Accuracy: 0.8168, Test Loss: 1.1311, Test Accuracy: 0.4268\n",
            "Epoch 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:05<00:00, 20.93s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/50, Train Loss: 0.7370, Train Accuracy: 0.8115, Test Loss: 0.9159, Test Accuracy: 0.6341\n",
            "Epoch 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:07<00:00, 21.19s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/50, Train Loss: 0.7373, Train Accuracy: 0.8115, Test Loss: 0.9895, Test Accuracy: 0.5488\n",
            "Epoch 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:06<00:00, 21.14s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/50, Train Loss: 0.7378, Train Accuracy: 0.8168, Test Loss: 0.9728, Test Accuracy: 0.5854\n",
            "Epoch 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.77s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/50, Train Loss: 0.7450, Train Accuracy: 0.8115, Test Loss: 0.8992, Test Accuracy: 0.6463\n",
            "Epoch 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:05<00:00, 20.97s/it]\n",
            "100%|██████████| 3/3 [00:22<00:00,  7.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/50, Train Loss: 0.7191, Train Accuracy: 0.8325, Test Loss: 1.0234, Test Accuracy: 0.5122\n",
            "Epoch 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:03<00:00, 20.53s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/50, Train Loss: 0.7149, Train Accuracy: 0.8325, Test Loss: 0.9878, Test Accuracy: 0.5488\n",
            "Epoch 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:08<00:00, 21.42s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/50, Train Loss: 0.7038, Train Accuracy: 0.8482, Test Loss: 0.8704, Test Accuracy: 0.6707\n",
            "Epoch 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:05<00:00, 20.94s/it]\n",
            "100%|██████████| 3/3 [00:22<00:00,  7.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/50, Train Loss: 0.6910, Train Accuracy: 0.8639, Test Loss: 1.0276, Test Accuracy: 0.5122\n",
            "Epoch 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:06<00:00, 21.02s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/50, Train Loss: 0.6871, Train Accuracy: 0.8743, Test Loss: 0.9572, Test Accuracy: 0.5610\n",
            "Epoch 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:05<00:00, 20.95s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/50, Train Loss: 0.6860, Train Accuracy: 0.8691, Test Loss: 0.8644, Test Accuracy: 0.6707\n",
            "Epoch 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:03<00:00, 20.59s/it]\n",
            "100%|██████████| 3/3 [00:22<00:00,  7.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/50, Train Loss: 0.6851, Train Accuracy: 0.8691, Test Loss: 1.0538, Test Accuracy: 0.4634\n",
            "Epoch 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:04<00:00, 20.71s/it]\n",
            "100%|██████████| 3/3 [00:21<00:00,  7.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/50, Train Loss: 0.6811, Train Accuracy: 0.8743, Test Loss: 1.0649, Test Accuracy: 0.4756\n",
            "Epoch 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [02:05<00:00, 20.86s/it]\n",
            "100%|██████████| 3/3 [00:20<00:00,  6.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/50, Train Loss: 0.6793, Train Accuracy: 0.8639, Test Loss: 0.8967, Test Accuracy: 0.6585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'GoogLeNetModified_audio_video_'+str(num_epochs)+'_'+str(_bs)+'_'+str(_lr))"
      ],
      "metadata": {
        "id": "9N8B8WXkUdJY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/"
      ],
      "metadata": {
        "id": "qdOvcYZea_DZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2688724-28a0-449c-b742-3bcfee6c92ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 46M\n",
            "-rw-r--r-- 1 root root    9 Mar  2 06:26 2DFAN4-11f355bf06.pth.tar\n",
            "drwx------ 6 root root 4.0K Mar  2 06:24 drive\n",
            "-rw-r--r-- 1 root root  46M Mar  2 08:34 GoogLeNetModified_audio_video_50_32_0.001\n",
            "drwxr-xr-x 1 root root 4.0K Feb 28 14:27 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp  'GoogLeNetModified_audio_video_50_32_0.001' '/content/drive/MyDrive/csci535/models'"
      ],
      "metadata": {
        "id": "VIsatL11bPU_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WYN9KsDs8lP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}