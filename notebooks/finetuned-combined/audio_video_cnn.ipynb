{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SP57JsruRqX5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/aashiarv/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import face_alignment\n",
    "#import dlib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oLkWoD6pRrAb"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = models.vgg16(pretrained=True)\n",
    "        # Modify the first layer to accept 2 channel input\n",
    "        self.features.features[0] = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Modify the final layer to output desired feature size\n",
    "        self.features.classifier[6] = nn.Linear(self.features.classifier[6].in_features, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gWDrEH00iv6H"
   },
   "outputs": [],
   "source": [
    "def extract_frame(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    mid_frame_index = frame_count // 2  # Index of the frame in the middle of the video\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, mid_frame_index)\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cap.release()\n",
    "        return frame\n",
    "    else:\n",
    "        cap.release()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_eeDIIORixs-"
   },
   "outputs": [],
   "source": [
    "def detect_face(frame):\n",
    "    mtcnn = MTCNN()\n",
    "    boxes, _ = mtcnn.detect(frame)\n",
    "    if boxes is not None:\n",
    "        # Assuming only one face in the frame\n",
    "        box = boxes[0]\n",
    "        x1, y1, x2, y2 = box\n",
    "        # Crop the frame to the detected face\n",
    "        cropped_frame = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "        return cropped_frame\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pWavua0jl3ds",
    "outputId": "d4df4606-2f56-4e69-c226-b3f4856f54f8"
   },
   "outputs": [],
   "source": [
    "# Function to download the pretrained face alignment model if it doesn't exist\n",
    "def download_face_alignment_model(url, save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        print(\"Downloading pretrained face alignment model...\")\n",
    "        response = requests.get(url)\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Download complete.\")\n",
    "device='cpu'\n",
    "# Specify the URL of the pretrained face alignment model\n",
    "face_alignment_model_url = \"https://github.com/1adrianb/face-alignment-models/releases/download/2.0.1/2DFAN4-11f355bf06.pth.tar\"\n",
    "\n",
    "# Download the pretrained face alignment model if it doesn't exist\n",
    "face_alignment_model_path = os.path.abspath(\"2DFAN4-11f355bf06.pth.tar\")\n",
    "download_face_alignment_model(face_alignment_model_url, face_alignment_model_path)\n",
    "\n",
    "# Initialize face alignment model\n",
    "fa = face_alignment.FaceAlignment(2, device=device,flip_input=False)  # 2 corresponds to 2D landmarks\n",
    "\n",
    "def align_face(frame):\n",
    "    # Perform face alignment\n",
    "    aligned_faces = fa.get_landmarks(frame)\n",
    "    if aligned_faces is not None:\n",
    "        aligned_face = aligned_faces[0]  # Assuming only one face in the frame\n",
    "        return aligned_face\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "o5gBfMkuitP0"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(frame):\n",
    "    # Convert the frame to a PIL Image\n",
    "    frame_pil = Image.fromarray(frame.astype('uint8'))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    frame_pil = frame_pil.convert('L')\n",
    "\n",
    "    # Resize and normalize the frame\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485], std=[0.229]),  # For grayscale images, only 1 channel\n",
    "    ])\n",
    "    img_tensor = transform(frame_pil)\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x5iAGoZ_yUMX"
   },
   "outputs": [],
   "source": [
    "def preprocess_spectrogram(image_path):\n",
    "    img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to match ResNet input size\n",
    "        transforms.ToTensor(),           # Convert to tensor\n",
    "    ])\n",
    "    img_tensor = transform(img)\n",
    "    # img_tensor = img_tensor.unsqueeze(0)  # Add batch dimension\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ONxd6uaQyYT8"
   },
   "outputs": [],
   "source": [
    "def load_spectrogram_dataset(input_folder):\n",
    "    X = []\n",
    "    y = []\n",
    "    # List all files in the input folder\n",
    "    files = os.listdir(input_folder)\n",
    "    # Iterate over files in the folder\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".png\"):  # Assuming mel spectrograms are stored as PNG files\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            img_tensor = preprocess_spectrogram(input_path)\n",
    "            X.append(img_tensor)\n",
    "            # Extract label from filename (assuming filename is in format \"abc_IEO_label_xyz.png\")\n",
    "            label = filename.split(\"_\")[2]\n",
    "            if label == \"HAP\":\n",
    "                y.append(0)\n",
    "            elif label == \"SAD\":\n",
    "                y.append(1)\n",
    "            elif label == \"ANG\":\n",
    "                y.append(2)\n",
    "            elif label == \"DIS\":\n",
    "                y.append(3)\n",
    "            elif label == \"FEA\":\n",
    "                y.append(4)\n",
    "            elif label == \"NEU\":\n",
    "                y.append(5)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RZPMwNWJi5p3"
   },
   "outputs": [],
   "source": [
    "def load_dataset(input_folder):\n",
    "    X = []\n",
    "    y = []\n",
    "    video_files = [file for file in os.listdir(input_folder) if file.endswith(\".flv\")]\n",
    "    for video_file in tqdm(video_files):\n",
    "        video_path = os.path.join(input_folder, video_file)\n",
    "        frame = extract_frame(video_path)\n",
    "        if frame is not None:\n",
    "            cropped_face = detect_face(frame)\n",
    "            if cropped_face is not None:\n",
    "                preprocessed_face = preprocess_image(cropped_face)\n",
    "                X.append(preprocessed_face)\n",
    "                label = video_file.split(\"_\")[2].split(\".\")[0]  # Adjusted to handle different file extensions\n",
    "                if label == \"HAP\":\n",
    "                    y.append(0)\n",
    "                elif label == \"SAD\":\n",
    "                    y.append(1)\n",
    "                elif label == \"ANG\":\n",
    "                    y.append(2)\n",
    "                elif label == \"DIS\":\n",
    "                    y.append(3)\n",
    "                elif label == \"FEA\":\n",
    "                    y.append(4)\n",
    "                elif label == \"NEU\":\n",
    "                    y.append(5)\n",
    "            else:\n",
    "                print(f\"No face detected in {video_file}. Skipping.\")\n",
    "        else:\n",
    "            print(f\"Failed to extract frame from {video_file}. Skipping.\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "O0bI2bJNzZ9r"
   },
   "outputs": [],
   "source": [
    "# Define the ConcatDataset class to concatenate video frame and spectrogram tensors\n",
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X1, X2, y, modality='multimodal', fullscale=False):\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        self.y = y\n",
    "        self.modality = modality\n",
    "        self.fullscale = fullscale\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.fullscale:\n",
    "            img1 = torch.from_numpy(self.X1[idx]).float()  # Convert numpy array to torch tensor\n",
    "            img2 = torch.from_numpy(self.X2[idx]).float()  # Convert numpy array to torch tensor\n",
    "            label = torch.tensor(self.y[idx])  # Convert numpy array to torch tensor\n",
    "        else:\n",
    "            img1 = torch.from_numpy(self.X1[idx]).float()  # Convert numpy array to torch tensor\n",
    "            img2 = torch.from_numpy(self.X2[idx]).float()  # Convert numpy array to torch tensor\n",
    "            label = torch.tensor(self.y[idx])  # Convert numpy array to torch tensor\n",
    "\n",
    "        concatenated_img = torch.cat((img1, img2), dim=0)  # Concatenate along 0 dimension\n",
    "        if self.modality == 'visual':\n",
    "            return img1, label\n",
    "        if self.modality == 'audio':\n",
    "            return img2, label\n",
    "        return concatenated_img, label # concatenate modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Q5--S5JwTTw1"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "        total_preds += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    accuracy = correct_preds / total_preds\n",
    "    return epoch_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ajpo8J6kTUjD"
   },
   "outputs": [],
   "source": [
    "def test_model(model, criterion, test_loader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "    epoch_loss = running_loss / len(test_loader.dataset)\n",
    "    accuracy = correct_preds / total_preds\n",
    "    return epoch_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D29Ahtfz2HAb",
    "outputId": "b216ccd4-3f4e-479a-87e6-07f9821502cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 7442\n",
      "Number of train samples (video): 5209 Number of test samples: 2233\n",
      "Number of train samples (audio): 5231 Number of test samples: 2242\n"
     ]
    }
   ],
   "source": [
    "_fullscale = True # Run fullscale experiment?\n",
    "\n",
    "# Define input_folder and input_folder_spec\n",
    "if _fullscale:\n",
    "  input_folder = 'videos_fullscale'\n",
    "  input_folder_spec = 'melspec_fullscale'\n",
    "else:\n",
    "  input_folder = '/content/drive/MyDrive/csci535_aashi/videos'\n",
    "  input_folder_spec = '/content/drive/MyDrive/csci535_aashi/melspec'\n",
    "\n",
    "# Check if input folder exists\n",
    "if not os.path.exists(input_folder):\n",
    "    print(\"Input folder does not exist.\")\n",
    "    sys.exit(1)\n",
    "# Check if input folder exists\n",
    "if not os.path.exists(input_folder_spec):\n",
    "    print(\"Input folder does not exist.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Load dataset and split into train and test sets\n",
    "\n",
    "if not _fullscale:\n",
    "  X, y = load_dataset(input_folder)\n",
    "  X_spec, y_spec = load_spectrogram_dataset(input_folder_spec)\n",
    "\n",
    "else:\n",
    "  # Load numpy arrays with memory-mapping\n",
    "  X = np.load('X.npy', mmap_mode='r')\n",
    "  y = np.load('y.npy', mmap_mode='r')\n",
    "  X_spec = np.load('X_spec.npy', mmap_mode='r')\n",
    "  y_spec = np.load('y_spec.npy', mmap_mode='r')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "print(f\"Total number of samples: {len(X)}\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Number of train samples (video): {len(X_train)}\", f\"Number of test samples: {len(X_test)}\")\n",
    "X_train_spec, X_test_spec, y_train_spec, y_test_spec = train_test_split(X_spec, y_spec, test_size=0.3, random_state=42)\n",
    "print(f\"Number of train samples (audio): {len(X_train_spec)}\", f\"Number of test samples: {len(X_test_spec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3xLVy9d2O5d",
    "outputId": "6c6091b3-505e-4ca1-ec80-c589ea46bc49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/aashiarv/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home1/aashiarv/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 32 lr: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = CNN(num_classes=6)  # 3 classes for HAPPY, SAD, ANGRY\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "_lr = 0.0001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=_lr)\n",
    "\n",
    "# Concatenate datasets\n",
    "train_dataset = ConcatDataset(X_train, X_train_spec, y_train)\n",
    "test_dataset = ConcatDataset(X_test, X_test_spec, y_test)\n",
    "\n",
    "# Create data loaders\n",
    "_bs = 32\n",
    "# train_loader = torch.utils.data.DataLoader(list(zip(X_train, y_train)), batch_size=_bs, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(list(zip(X_test, y_test)), batch_size=_bs)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=_bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=_bs)\n",
    "\n",
    "\n",
    "print(f\"Batch size: {_bs}\", f\"lr: {_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0upA86L2S47",
    "outputId": "811d82a8-6bab-4d2e-b3c7-2035b39d5b7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:19<00:00,  8.32it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 1.7913, Train Accuracy: 0.1818, Test Loss: 1.7916, Test Accuracy: 0.1711\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.60it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Train Loss: 1.7835, Train Accuracy: 0.1814, Test Loss: 1.7635, Test Accuracy: 0.2262\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.62it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Train Loss: 1.7613, Train Accuracy: 0.2283, Test Loss: 1.7176, Test Accuracy: 0.2911\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.62it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Train Loss: 1.7516, Train Accuracy: 0.2448, Test Loss: 1.6470, Test Accuracy: 0.3609\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.61it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 1.6836, Train Accuracy: 0.3194, Test Loss: 1.7052, Test Accuracy: 0.2897\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.61it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Train Loss: 1.6307, Train Accuracy: 0.3864, Test Loss: 1.6092, Test Accuracy: 0.4102\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.58it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Train Loss: 1.6184, Train Accuracy: 0.4053, Test Loss: 1.5734, Test Accuracy: 0.4505\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.56it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 1.5946, Train Accuracy: 0.4289, Test Loss: 1.5494, Test Accuracy: 0.4734\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Train Loss: 1.5779, Train Accuracy: 0.4415, Test Loss: 1.5941, Test Accuracy: 0.4281\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.54it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Train Loss: 1.5399, Train Accuracy: 0.4845, Test Loss: 1.5367, Test Accuracy: 0.4948\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.53it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Train Loss: 1.5211, Train Accuracy: 0.5085, Test Loss: 1.5201, Test Accuracy: 0.5159\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Train Loss: 1.5018, Train Accuracy: 0.5329, Test Loss: 1.4907, Test Accuracy: 0.5468\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Train Loss: 1.4827, Train Accuracy: 0.5546, Test Loss: 1.4625, Test Accuracy: 0.5764\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.54it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Train Loss: 1.4544, Train Accuracy: 0.5805, Test Loss: 1.4902, Test Accuracy: 0.5455\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 1.4469, Train Accuracy: 0.5903, Test Loss: 1.4904, Test Accuracy: 0.5464\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Train Loss: 1.4352, Train Accuracy: 0.6005, Test Loss: 1.4309, Test Accuracy: 0.6055\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.54it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Train Loss: 1.4391, Train Accuracy: 0.5969, Test Loss: 1.4672, Test Accuracy: 0.5719\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.54it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Train Loss: 1.4476, Train Accuracy: 0.5949, Test Loss: 1.4470, Test Accuracy: 0.5867\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.54it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Train Loss: 1.4244, Train Accuracy: 0.6139, Test Loss: 1.4407, Test Accuracy: 0.6001\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.53it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Train Loss: 1.4145, Train Accuracy: 0.6268, Test Loss: 1.4236, Test Accuracy: 0.6158\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.54it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Train Loss: 1.3694, Train Accuracy: 0.6711, Test Loss: 1.5017, Test Accuracy: 0.5378\n",
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.54it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Train Loss: 1.4114, Train Accuracy: 0.6281, Test Loss: 1.4676, Test Accuracy: 0.5705\n",
      "Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.54it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Train Loss: 1.3796, Train Accuracy: 0.6600, Test Loss: 1.4321, Test Accuracy: 0.6010\n",
      "Epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Train Loss: 1.3568, Train Accuracy: 0.6823, Test Loss: 1.4571, Test Accuracy: 0.5808\n",
      "Epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Train Loss: 1.3565, Train Accuracy: 0.6819, Test Loss: 1.4052, Test Accuracy: 0.6364\n",
      "Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.54it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Train Loss: 1.3434, Train Accuracy: 0.6982, Test Loss: 1.4498, Test Accuracy: 0.5911\n",
      "Epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Train Loss: 1.3379, Train Accuracy: 0.7036, Test Loss: 1.4157, Test Accuracy: 0.6238\n",
      "Epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Train Loss: 1.3739, Train Accuracy: 0.6660, Test Loss: 1.4399, Test Accuracy: 0.6023\n",
      "Epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Train Loss: 1.3853, Train Accuracy: 0.6560, Test Loss: 1.4623, Test Accuracy: 0.5768\n",
      "Epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Train Loss: 1.3799, Train Accuracy: 0.6615, Test Loss: 1.4378, Test Accuracy: 0.6014\n",
      "Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Train Loss: 1.3485, Train Accuracy: 0.6934, Test Loss: 1.4434, Test Accuracy: 0.5974\n",
      "Epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Train Loss: 1.3486, Train Accuracy: 0.6936, Test Loss: 1.4242, Test Accuracy: 0.6135\n",
      "Epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Train Loss: 1.3410, Train Accuracy: 0.7001, Test Loss: 1.4216, Test Accuracy: 0.6198\n",
      "Epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.56it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Train Loss: 1.3319, Train Accuracy: 0.7088, Test Loss: 1.4147, Test Accuracy: 0.6274\n",
      "Epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.56it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Train Loss: 1.3086, Train Accuracy: 0.7333, Test Loss: 1.4134, Test Accuracy: 0.6288\n",
      "Epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.56it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Train Loss: 1.3309, Train Accuracy: 0.7120, Test Loss: 1.4086, Test Accuracy: 0.6323\n",
      "Epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.56it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Train Loss: 1.3807, Train Accuracy: 0.6602, Test Loss: 1.4418, Test Accuracy: 0.6001\n",
      "Epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.56it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Train Loss: 1.3701, Train Accuracy: 0.6713, Test Loss: 1.4257, Test Accuracy: 0.6158\n",
      "Epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.55it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Train Loss: 1.3930, Train Accuracy: 0.6483, Test Loss: 1.4333, Test Accuracy: 0.6068\n",
      "Epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.57it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Train Loss: 1.3926, Train Accuracy: 0.6491, Test Loss: 1.4796, Test Accuracy: 0.5607\n",
      "Epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.58it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Train Loss: 1.3861, Train Accuracy: 0.6552, Test Loss: 1.4185, Test Accuracy: 0.6216\n",
      "Epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.57it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Train Loss: 1.3987, Train Accuracy: 0.6448, Test Loss: 1.4924, Test Accuracy: 0.5499\n",
      "Epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.57it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Train Loss: 1.3842, Train Accuracy: 0.6581, Test Loss: 1.4911, Test Accuracy: 0.5513\n",
      "Epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.56it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Train Loss: 1.3868, Train Accuracy: 0.6543, Test Loss: 1.4741, Test Accuracy: 0.5683\n",
      "Epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.58it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Train Loss: 1.4273, Train Accuracy: 0.6147, Test Loss: 1.4535, Test Accuracy: 0.5889\n",
      "Epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.57it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Train Loss: 1.4293, Train Accuracy: 0.6134, Test Loss: 1.4859, Test Accuracy: 0.5553\n",
      "Epoch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.57it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Train Loss: 1.4442, Train Accuracy: 0.5982, Test Loss: 1.5043, Test Accuracy: 0.5374\n",
      "Epoch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.57it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Train Loss: 1.4698, Train Accuracy: 0.5736, Test Loss: 1.5748, Test Accuracy: 0.4680\n",
      "Epoch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.58it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Train Loss: 1.5134, Train Accuracy: 0.5287, Test Loss: 1.6223, Test Accuracy: 0.4201\n",
      "Epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.57it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Train Loss: 1.6099, Train Accuracy: 0.4329, Test Loss: 1.5713, Test Accuracy: 0.4716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch \" + str(epoch))\n",
    "    train_loss, train_accuracy = train_model(model, criterion, optimizer, train_loader, device)\n",
    "    test_loss, test_accuracy = test_model(model, criterion, test_loader, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9N8B8WXkUdJY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'vgg16_audio_video_'+str(num_epochs)+'_'+str(_bs)+'_'+str(_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIsatL11bPU_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WYN9KsDs8lP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.12.2 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
